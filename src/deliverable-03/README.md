# Deliverable 3 Summary

This model is deployed on HuggingFace: https://huggingface.co/joshua-gottlieb/tensorflow-credibility_predictor-v2/tree/main

The data was downloaded using [Data-from-Github.ipnyb](https://github.com/JoshuaGottlieb/Chatbot-Credibility-Scorer/blob/main/src/deliverable-03/Data-From-Github.ipynb) and saved as [prompts_and_ratings.csv](https://github.com/JoshuaGottlieb/Chatbot-Credibility-Scorer/blob/main/src/deliverable-03/prompts_and_ratings.csv).

The primary notebook for the Tensorflow model can be found at [Tensorflow Evaluator.ipynb](https://github.com/JoshuaGottlieb/Chatbot-Credibility-Scorer/blob/main/src/deliverable-03/Tensorflow-Evaluator.ipynb). The user prompts are transformed into 48 dimensional vectors using the 'all-MiniLM-L6-v2' model from SentenceTransformers with binary precision. This tokenizer was pickled as tokenizer.pkl under [saved_model](https://github.com/JoshuaGottlieb/Chatbot-Credibility-Scorer/tree/main/src/deliverable-03/saved_model).

Three models were trained. Two of the models are available under [tf_models.py](https://github.com/JoshuaGottlieb/Chatbot-Credibility-Scorer/blob/main/src/deliverable-03/tf_models.py). The first model (model_v1) uses 4 Dense layers to process the text embeddings, with neuron counts of (256, 128, 128, 64), respectively. A variety of neural nets were tested. Starting with more neurons (4096) caused the model to heavily overfit on the training data. Starting at fewer neurons (64-128) made the model too simple and led to underfitting and poor performance. Longer neural nets with more layers tended to cause the model to plateau and slightly underfit, as it would stop learning after the first few epochs. This model was trained for 80 epochs, each of which was saved in [checkpoint/model_v1](https://github.com/JoshuaGottlieb/Chatbot-Credibility-Scorer/tree/main/src/deliverable-03/checkpoint/model_v1). The best performing model (epoch 30) based on validation accuracy was extracted and saved as model_v1.keras under [saved_model](https://github.com/JoshuaGottlieb/Chatbot-Credibility-Scorer/tree/main/src/deliverable-03/saved_model). This first version attained a maximum validation accuracy of 0.7049.

The second tensorflow model is available in the same python script. It utilizes the same structure of 4 dense layers with the same neuron counts, but it utilizes ElasticNet (L1 + L2) regularization for each of the Dense layers to reduce overfitting on the training data. The model also uses an ExponentialDecay learning rate scheduler to help the model converge while training. This model was also trained for 80 epochs, each of which was saved in [checkpoint/model_v2](https://github.com/JoshuaGottlieb/Chatbot-Credibility-Scorer/tree/main/src/deliverable-03/checkpoint/model_v2). The best perfomring model (epoch 11) based on validation accuracy was exrtacted and saved as model_v2.keras under [saved_model](https://github.com/JoshuaGottlieb/Chatbot-Credibility-Scorer/tree/main/src/deliverable-03/saved_model). This second version attained a maximum validation accuracy of 0.7213. Additionally, the regularization helped prevent the model from overfitting.

The final model tested was a base support vector classifier (SVC) from scikit-learn. This model was not tuned and was run using base parameters and attained a validation accuracy of 0.5902, which is much worse than either of the neural networks, albeit using a vastly simpler model. All three models and the tokenizer were pushed to the HuggingFace repo listed at the top of this README.
